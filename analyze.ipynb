{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_gathering import historical_quiz_data, historical_quiz_df, combined_df, current_quiz_df, current_quiz_data\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  quiz_id                       user_id  \\\n",
      "0   336497       51  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "1   336448        6  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "2   333330       51  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "3   333242        6  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "4   329504       51  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "5   328488       57  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "6   328414        6  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "7   321514       20  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "8   320963       24  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "9   320916       18  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "10  315179       25  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "11  315081       18  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "12  257774       58  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "13  195808       50  YcDFSO4ZukTJnnFMgRNVwZTE4j42   \n",
      "\n",
      "                     submitted_at                     created_at  \\\n",
      "0   2025-01-17T15:30:18.027+05:30  2025-01-17T15:30:18.044+05:30   \n",
      "1   2025-01-17T15:17:44.042+05:30  2025-01-17T15:17:44.056+05:30   \n",
      "2   2025-01-16T20:13:19.682+05:30  2025-01-16T20:13:19.699+05:30   \n",
      "3   2025-01-16T20:00:11.562+05:30  2025-01-16T20:00:11.573+05:30   \n",
      "4   2025-01-15T20:34:39.462+05:30  2025-01-15T20:34:39.478+05:30   \n",
      "5   2025-01-15T15:57:12.791+05:30  2025-01-15T15:57:12.800+05:30   \n",
      "6   2025-01-15T15:36:46.410+05:30  2025-01-15T15:36:46.420+05:30   \n",
      "7   2025-01-13T16:10:03.743+05:30  2025-01-13T16:10:03.753+05:30   \n",
      "8   2025-01-13T13:28:12.784+05:30  2025-01-13T13:28:12.795+05:30   \n",
      "9   2025-01-13T13:12:40.687+05:30  2025-01-13T13:12:40.695+05:30   \n",
      "10  2025-01-11T21:20:08.641+05:30  2025-01-11T21:20:08.652+05:30   \n",
      "11  2025-01-11T21:03:43.251+05:30  2025-01-11T21:03:43.262+05:30   \n",
      "12  2024-12-28T22:58:52.969+05:30  2024-12-28T22:58:53.122+05:30   \n",
      "13  2024-12-11T20:36:44.822+05:30  2024-12-11T20:36:44.863+05:30   \n",
      "\n",
      "                       updated_at  score  trophy_level  accuracy  speed  ...  \\\n",
      "0   2025-01-17T15:30:18.044+05:30    108             2      90.0    100  ...   \n",
      "1   2025-01-17T15:17:44.056+05:30     92             1     100.0    100  ...   \n",
      "2   2025-01-16T20:13:19.699+05:30    116             2      96.0    100  ...   \n",
      "3   2025-01-16T20:00:11.573+05:30     36             2      90.0    100  ...   \n",
      "4   2025-01-15T20:34:39.478+05:30     36             3      31.0     96  ...   \n",
      "5   2025-01-15T15:57:12.800+05:30     40             3      38.0     86  ...   \n",
      "6   2025-01-15T15:36:46.420+05:30     36             3      50.0     78  ...   \n",
      "7   2025-01-13T16:10:03.753+05:30     12             2      30.0    100  ...   \n",
      "8   2025-01-13T13:28:12.795+05:30     76             2     100.0     95  ...   \n",
      "9   2025-01-13T13:12:40.695+05:30     40             1     100.0    100  ...   \n",
      "10  2025-01-11T21:20:08.652+05:30    112             2      93.0    100  ...   \n",
      "11  2025-01-11T21:03:43.262+05:30     64             3      84.0     86  ...   \n",
      "12  2024-12-28T22:58:53.122+05:30     52             2      43.0    100  ...   \n",
      "13  2024-12-11T20:36:44.863+05:30     24             3      66.0     90  ...   \n",
      "\n",
      "                         ended_at duration  better_than  total_questions  \\\n",
      "0   2025-01-17T15:30:15.000+05:30    15:00          107              100   \n",
      "1   2025-01-17T15:17:41.000+05:30    15:00          395               23   \n",
      "2   2025-01-16T20:13:18.000+05:30    15:00          115              100   \n",
      "3   2025-01-16T20:00:09.000+05:30    15:00          152               23   \n",
      "4   2025-01-15T20:34:38.000+05:30    15:00           35              100   \n",
      "5   2025-01-15T15:57:11.000+05:30    15:00           43               89   \n",
      "6   2025-01-15T15:36:45.000+05:30    15:00          152               23   \n",
      "7   2025-01-13T16:10:02.000+05:30    15:00           18               59   \n",
      "8   2025-01-13T13:28:11.000+05:30    15:00          375               20   \n",
      "9   2025-01-13T13:12:39.000+05:30    15:00          177               22   \n",
      "10  2025-01-11T21:20:07.000+05:30    15:00          270               41   \n",
      "11  2025-01-11T21:03:42.000+05:30    15:00          286               22   \n",
      "12  2024-12-28T22:58:49.000+05:30    15:00           92               55   \n",
      "13  2024-12-11T20:36:42.000+05:30    15:00           23              100   \n",
      "\n",
      "              rank_text mistakes_corrected initial_mistake_count  \\\n",
      "0    Topic Rank - #-171                  9                    12   \n",
      "1   Topic Rank - #-9140                  3                     3   \n",
      "2    Topic Rank - #-418                 11                    12   \n",
      "3   Topic Rank - #-1598                  1                     2   \n",
      "4    Topic Rank - #2023                  0                    20   \n",
      "5    Topic Rank - #1810                  0                    16   \n",
      "6   Topic Rank - #-1598                  0                     9   \n",
      "7    Topic Rank - #2556                  0                     7   \n",
      "8   Topic Rank - #-8479                  4                     4   \n",
      "9   Topic Rank - #-2380                  0                     0   \n",
      "10  Topic Rank - #-5215                 12                    14   \n",
      "11  Topic Rank - #-5764                  0                     3   \n",
      "12    Topic Rank - #301                  0                    17   \n",
      "13   Topic Rank - #2392                  0                     3   \n",
      "\n",
      "                                         response_map  \\\n",
      "0   {'2523': 10109, '2529': 10130, '2533': 10149, ...   \n",
      "1   {'48': 192, '49': 197, '50': 199, '51': 203, '...   \n",
      "2   {'2523': 10109, '2525': 10117, '2528': 10127, ...   \n",
      "3   {'49': 197, '52': 208, '53': 212, '54': 217, '...   \n",
      "4   {'2521': 10099, '2523': 10107, '2532': 10145, ...   \n",
      "5   {'3043': 12184, '3044': 12186, '3046': 12194, ...   \n",
      "6   {'48': 193, '49': 197, '50': 202, '51': 203, '...   \n",
      "7   {'473': 1893, '474': 1898, '475': 1901, '487':...   \n",
      "8   {'770': 3084, '771': 3085, '772': 3091, '773':...   \n",
      "9   {'612': 2451, '613': 2454, '614': 2460, '619':...   \n",
      "10  {'790': 3160, '793': 3172, '794': 3177, '796':...   \n",
      "11  {'611': 2447, '612': 2451, '613': 2454, '614':...   \n",
      "12  {'3132': 12542, '3135': 12554, '3137': 12561, ...   \n",
      "13  {'2417': 9684, '2425': 9715, '2435': 9754, '24...   \n",
      "\n",
      "                                                 quiz  \\\n",
      "0   {'id': 51, 'name': None, 'title': 'Human Physi...   \n",
      "1   {'id': 6, 'name': None, 'title': 'Human Physio...   \n",
      "2   {'id': 51, 'name': None, 'title': 'Human Physi...   \n",
      "3   {'id': 6, 'name': None, 'title': 'Human Physio...   \n",
      "4   {'id': 51, 'name': None, 'title': 'Human Physi...   \n",
      "5   {'id': 57, 'name': None, 'title': 'Reproductio...   \n",
      "6   {'id': 6, 'name': None, 'title': 'Human Physio...   \n",
      "7   {'id': 20, 'name': None, 'title': 'PRINCIPLES ...   \n",
      "8   {'id': 24, 'name': None, 'title': 'MICROBES IN...   \n",
      "9   {'id': 18, 'name': None, 'title': 'REPRODUCTIV...   \n",
      "10  {'id': 25, 'name': None, 'title': 'HUMAN HEALT...   \n",
      "11  {'id': 18, 'name': None, 'title': 'REPRODUCTIV...   \n",
      "12  {'id': 58, 'name': None, 'title': 'Reproductio...   \n",
      "13  {'id': 50, 'name': None, 'title': 'Human Physi...   \n",
      "\n",
      "                                       topic  \n",
      "0                Body Fluids and Circulation  \n",
      "1               Body Fluids and Circulation   \n",
      "2                Body Fluids and Circulation  \n",
      "3               Body Fluids and Circulation   \n",
      "4                Body Fluids and Circulation  \n",
      "5                         Human Reproduction  \n",
      "6               Body Fluids and Circulation   \n",
      "7   principles of inheritance and variation   \n",
      "8                  microbes in human welfare  \n",
      "9                       reproductive health   \n",
      "10                 human health and disease   \n",
      "11                      reproductive health   \n",
      "12                       Reproductive Health  \n",
      "13              Respiration and Gas Exchange  \n",
      "\n",
      "[14 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(historical_quiz_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance trends by topic:\n",
      "                                      topic   avg_score  avg_accuracy  \\\n",
      "0               Body Fluids and Circulation   86.666667     72.333333   \n",
      "1              Body Fluids and Circulation    54.666667     80.000000   \n",
      "2                        Human Reproduction   40.000000     38.000000   \n",
      "3                       Reproductive Health   52.000000     43.000000   \n",
      "4              Respiration and Gas Exchange   24.000000     66.000000   \n",
      "5                 human health and disease   112.000000     93.000000   \n",
      "6                 microbes in human welfare   76.000000    100.000000   \n",
      "7  principles of inheritance and variation    12.000000     30.000000   \n",
      "8                      reproductive health    52.000000     92.000000   \n",
      "\n",
      "    avg_speed  avg_correct_answers  avg_incorrect_answers  avg_total_questions  \n",
      "0   98.666667            21.666667               8.000000                100.0  \n",
      "1   92.666667            13.666667               3.333333                 23.0  \n",
      "2   86.000000            10.000000              16.000000                 89.0  \n",
      "3  100.000000            13.000000              17.000000                 55.0  \n",
      "4   90.000000             6.000000               3.000000                100.0  \n",
      "5  100.000000            28.000000               2.000000                 41.0  \n",
      "6   95.000000            19.000000               0.000000                 20.0  \n",
      "7  100.000000             3.000000               7.000000                 59.0  \n",
      "8   93.000000            13.000000               1.500000                 22.0  \n"
     ]
    }
   ],
   "source": [
    "#to analyze trends based on topic column we must extract it from the nested dict quiz\n",
    "historical_quiz_df['topic'] = historical_quiz_df['quiz'].apply(lambda x: x['topic'])\n",
    "historical_quiz_df['total_questions'] = historical_quiz_df['quiz'].apply(lambda x: x['questions_count'])\n",
    "\n",
    "#convert % to a numeric typr for easier calcualtion\n",
    "historical_quiz_df['accuracy'] = historical_quiz_df['accuracy'].apply(lambda x: float(str(x).replace('%', '')) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "#calculate trends in historical data\n",
    "\n",
    "#make sure to handle non numeric or missing values so it doesnt intefere with the calcualtion\n",
    "\n",
    "numeric_columns = ['score', 'accuracy', 'speed', 'correct_answers', 'incorrect_answers', 'total_questions']\n",
    "for column in numeric_columns:\n",
    "    historical_quiz_df[column] = pd.to_numeric(historical_quiz_df[column], errors='coerce')\n",
    "\n",
    "\n",
    "trends = historical_quiz_df.groupby('topic').agg({\n",
    "    'score':'mean',\n",
    "    'accuracy':'mean',\n",
    "    'speed':'mean',\n",
    "    'correct_answers':'mean',\n",
    "    'incorrect_answers':'mean',\n",
    "    'total_questions':'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "trends.rename(columns={\n",
    "    'score':'avg_score',\n",
    "    'accuracy': 'avg_accuracy',\n",
    "    'speed': 'avg_speed',\n",
    "    'correct_answers': 'avg_correct_answers',\n",
    "    'incorrect_answers': 'avg_incorrect_answers',\n",
    "    'total_questions':'avg_total_questions'\n",
    "    }, inplace=True)\n",
    "\n",
    "print(\"performance trends by topic:\")\n",
    "print(trends)\n",
    "\n",
    "trends.to_csv('trends_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No historical data available for topic: Structural Organisation in Animals\n",
      "\n",
      "Comparison of Recent Submission with Historical Trends:\n"
     ]
    }
   ],
   "source": [
    "# we must compare the recent one to previous trends \n",
    "\n",
    "def compare_recent_to_trends(recent_submission, trends):\n",
    "    # extract the topic of the recent submission\n",
    "    recent_topic = recent_submission['quiz']['topic']\n",
    "    \n",
    "    # find the corresponding row in the trends dataFrame\n",
    "    topic_trend = trends[trends['topic'] == recent_topic]\n",
    "    \n",
    "    if topic_trend.empty:\n",
    "        print(f\"No historical data available for topic: {recent_topic}\")\n",
    "        return None\n",
    "    \n",
    "    # create a comparison dictionary\n",
    "    comparison = {\n",
    "        'topic': recent_topic,\n",
    "        'recent_score': recent_submission['score'],\n",
    "        'avg_score': topic_trend['avg_score'].values[0],\n",
    "        'recent_accuracy': float(recent_submission['accuracy'].replace('%', '')),\n",
    "        'avg_accuracy': topic_trend['avg_accuracy'].values[0],\n",
    "        'recent_speed': recent_submission['speed'],\n",
    "        'avg_speed': topic_trend['avg_speed'].values[0],\n",
    "        'recent_correct_answers': recent_submission['correct_answers'],\n",
    "        'avg_correct_answers': topic_trend['avg_correct_answers'].values[0],\n",
    "        'recent_incorrect_answers': recent_submission['incorrect_answers'],\n",
    "        'avg_incorrect_answers': topic_trend['avg_incorrect_answers'].values[0],\n",
    "    }\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "# compare recent quiz submission to historical trends\n",
    "comparison_result = compare_recent_to_trends(current_quiz_df, trends)\n",
    "\n",
    "# display the comparison\n",
    "print(\"\\nComparison of Recent Submission with Historical Trends:\")\n",
    "if comparison_result:\n",
    "    for key, value in comparison_result.items():\n",
    "        print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 90. 100.  96.  31.  38.  50.  30.  93.  84.  43.  66.]\n",
      "[ 72.33333333  80.          38.          43.          66.\n",
      "  93.         100.          30.          92.        ]\n"
     ]
    }
   ],
   "source": [
    "# Check for non-numeric values in accuracy\n",
    "print(historical_quiz_df['accuracy'].unique())\n",
    "print(trends['avg_accuracy'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Suggestions for Improvement:\n",
      "No suggestions needed. Keep up the good work!\n"
     ]
    }
   ],
   "source": [
    "# suggest areas of improvement based on comparison\n",
    "def suggest_improvements(comparison):\n",
    "    if not comparison:\n",
    "        return None\n",
    "    \n",
    "    suggestions = []\n",
    "    \n",
    "    # analyze performance and provide feedback\n",
    "    if comparison['recent_score'] < comparison['avg_score']:\n",
    "        suggestions.append(f\"Try to improve your score. Recent: {comparison['recent_score']}, Avg: {comparison['avg_score']}\")\n",
    "    \n",
    "    if comparison['recent_accuracy'] < comparison['avg_accuracy']:\n",
    "        suggestions.append(f\"Focus on improving accuracy. Recent: {comparison['recent_accuracy']}%, Avg: {comparison['avg_accuracy']}%\")\n",
    "    \n",
    "    if comparison['recent_speed'] < comparison['avg_speed']:\n",
    "        suggestions.append(f\"Work on increasing speed. Recent: {comparison['recent_speed']}, Avg: {comparison['avg_speed']}\")\n",
    "    \n",
    "    if comparison['recent_correct_answers'] < comparison['avg_correct_answers']:\n",
    "        suggestions.append(f\"Practice more to increase the number of correct answers. Recent: {comparison['recent_correct_answers']}, Avg: {comparison['avg_correct_answers']}\")\n",
    "    \n",
    "    if comparison['recent_incorrect_answers'] > comparison['avg_incorrect_answers']:\n",
    "        suggestions.append(f\"Try to reduce mistakes. Recent: {comparison['recent_incorrect_answers']}, Avg: {comparison['avg_incorrect_answers']}\")\n",
    "    \n",
    "    return suggestions\n",
    "\n",
    "# generate suggestions for improvement\n",
    "improvement_suggestions = suggest_improvements(comparison_result)\n",
    "\n",
    "# display improvement suggestions\n",
    "print(\"\\nSuggestions for Improvement:\")\n",
    "if improvement_suggestions:\n",
    "    for suggestion in improvement_suggestions:\n",
    "        print(f\"- {suggestion}\")\n",
    "else:\n",
    "    print(\"No suggestions needed. Keep up the good work!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(comparison_result):\n",
    "    if not comparison_result:\n",
    "        return {\"message\": \"No data available for recommendations.\"}\n",
    "\n",
    "    recommendations = {}\n",
    "    weak_topics = []\n",
    "    strong_topics = []\n",
    "\n",
    "    # analyze weak and strong points\n",
    "    if comparison_result['recent_score'] < comparison_result['avg_score']:\n",
    "        weak_topics.append({\n",
    "            \"topic\": comparison_result['topic'],\n",
    "            \"reason\": f\"Recent score ({comparison_result['recent_score']}) is below the average ({comparison_result['avg_score']}).\",\n",
    "            \"action\": \"Revise topic fundamentals and attempt related MCQs.\"\n",
    "        })\n",
    "\n",
    "    if comparison_result['recent_accuracy'] < comparison_result['avg_accuracy']:\n",
    "        weak_topics.append({\n",
    "            \"topic\": comparison_result['topic'],\n",
    "            \"reason\": f\"Accuracy ({comparison_result['recent_accuracy']}%) is below the average ({comparison_result['avg_accuracy']}%).\",\n",
    "            \"action\": \"Review incorrect answers and focus on weak question types.\"\n",
    "        })\n",
    "\n",
    "    if comparison_result['recent_speed'] > comparison_result['avg_speed']:\n",
    "        weak_topics.append({\n",
    "            \"topic\": comparison_result['topic'],\n",
    "            \"reason\": f\"Speed ({comparison_result['recent_speed']}) is slower than the average ({comparison_result['avg_speed']}).\",\n",
    "            \"action\": \"Practice timed quizzes to improve response speed.\"\n",
    "        })\n",
    "\n",
    "    # strong topics\n",
    "    if comparison_result['recent_score'] >= comparison_result['avg_score']:\n",
    "        strong_topics.append({\n",
    "            \"topic\": comparison_result['topic'],\n",
    "            \"reason\": f\"Consistent or above-average score ({comparison_result['recent_score']}).\",\n",
    "            \"action\": \"Maintain focus on this topic to keep improving.\"\n",
    "        })\n",
    "\n",
    "    recommendations['weak_topics'] = weak_topics\n",
    "    recommendations['strong_topics'] = strong_topics\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_student_persona(historical_data):\n",
    "    total_quizzes = len(historical_data)\n",
    "    avg_score = historical_data['score'].mean()\n",
    "    avg_accuracy = historical_data['accuracy'].mean()\n",
    "\n",
    "    # label by behavior\n",
    "    if avg_score > 80 and avg_accuracy > 90:\n",
    "        persona = \"Top Performer\"\n",
    "        description = \"Consistently excels with high scores and accuracy.\"\n",
    "    elif avg_score > 60 and avg_accuracy > 70:\n",
    "        persona = \"Strategic Learner\"\n",
    "        description = \"Steady performer with room for improvement in specific areas.\"\n",
    "    elif avg_score < 50 or avg_accuracy < 50:\n",
    "        persona = \"Needs Improvement\"\n",
    "        description = \"Struggles with performance consistency. Needs to work on fundamentals.\"\n",
    "\n",
    "    # identify dominant subject\n",
    "    dominant_topic = historical_data.groupby('topic')['score'].mean().idxmax()\n",
    "\n",
    "    return {\n",
    "        \"persona\": persona,\n",
    "        \"description\": description,\n",
    "        \"dominant_topic\": dominant_topic,\n",
    "        \"avg_score\": avg_score,\n",
    "        \"avg_accuracy\": avg_accuracy\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_performance(historical_quiz_df, trends):\n",
    "    # average score by topic\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=trends, x='topic', y='avg_score', palette='coolwarm')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title('Average Score by Topic')\n",
    "    plt.xlabel('Topic')\n",
    "    plt.ylabel('Average Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # trends in performance over time\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=historical_quiz_df, x='date', y='score', marker='o', label='Score')\n",
    "    sns.lineplot(data=historical_quiz_df, x='date', y='accuracy', marker='o', label='Accuracy (%)')\n",
    "    plt.title('Performance Trends Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# FastAPI app instance\n",
    "app = FastAPI()\n",
    "\n",
    "# Historical trends (example data)\n",
    "trends = pd.DataFrame({\n",
    "    \"topic\": [\"Body Fluids and Circulation\", \"Respiration and Gas Exchange\"],\n",
    "    \"avg_score\": [85, 70],\n",
    "    \"avg_accuracy\": [80.0, 75.0],\n",
    "    \"avg_speed\": [10, 15],\n",
    "    \"avg_correct_answers\": [20, 18],\n",
    "    \"avg_incorrect_answers\": [5, 7],\n",
    "})\n",
    "\n",
    "# Pydantic models\n",
    "class Quiz(BaseModel):\n",
    "    topic: str\n",
    "\n",
    "class QuizSubmission(BaseModel):\n",
    "    quiz: Quiz\n",
    "    score: float\n",
    "    accuracy: str\n",
    "    speed: int\n",
    "    correct_answers: int\n",
    "    incorrect_answers: int\n",
    "\n",
    "@app.post(\"/analyze\")\n",
    "def analyze_performance(data: QuizSubmission):\n",
    "    logging.debug(f\"Received data: {data}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract and clean recent submission\n",
    "        recent_topic = data.quiz.topic\n",
    "        recent_accuracy = float(data.accuracy.replace('%', '').strip())\n",
    "\n",
    "        # Find the corresponding topic in trends\n",
    "        topic_trend = trends[trends[\"topic\"] == recent_topic]\n",
    "        if topic_trend.empty:\n",
    "            raise HTTPException(status_code=404, detail=f\"No historical data available for topic: {recent_topic}\")\n",
    "\n",
    "        # Compare with trends\n",
    "        comparison = {\n",
    "            \"topic\": recent_topic,\n",
    "            \"recent_score\": data.score,\n",
    "            \"avg_score\": topic_trend[\"avg_score\"].values[0],\n",
    "            \"recent_accuracy\": recent_accuracy,\n",
    "            \"avg_accuracy\": topic_trend[\"avg_accuracy\"].values[0],\n",
    "            \"recent_speed\": data.speed,\n",
    "            \"avg_speed\": topic_trend[\"avg_speed\"].values[0],\n",
    "            \"recent_correct_answers\": data.correct_answers,\n",
    "            \"avg_correct_answers\": topic_trend[\"avg_correct_answers\"].values[0],\n",
    "            \"recent_incorrect_answers\": data.incorrect_answers,\n",
    "            \"avg_incorrect_answers\": topic_trend[\"avg_incorrect_answers\"].values[0],\n",
    "        }\n",
    "\n",
    "        return {\"comparison\": comparison}\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error occurred: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from uvicorn import Config, Server\n",
    "\n",
    "#config = Config(app=app, host=\"127.0.0.1\", port=8000)\n",
    "#server = Server(config)\n",
    "#await server.serve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
